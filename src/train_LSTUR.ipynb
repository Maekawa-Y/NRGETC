{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df293530-be14-463b-ba62-99b7710d82a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset import BaseDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "from config import model_name\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "from evaluate import evaluate\n",
    "import importlib\n",
    "import datetime\n",
    "from view import Graph\n",
    "\n",
    "try:\n",
    "    Model = getattr(importlib.import_module(f\"model.{model_name}\"), model_name)\n",
    "    config = getattr(importlib.import_module('config'), f\"{model_name}Config\")\n",
    "    print(f\"model : {model_name}\")\n",
    "except AttributeError:\n",
    "    print(f\"{model_name} not included!\")\n",
    "    exit()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"mode : GPU_mode\")\n",
    "else:\n",
    "    print(f\"mode : CPU_mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d19dcfaa-e324-4ca1-8bba-268975a7c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_loss = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss:\n",
    "            early_stop = False\n",
    "            get_better = True\n",
    "            self.counter = 0\n",
    "            self.best_loss = val_loss\n",
    "        else:\n",
    "            get_better = False\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                early_stop = True\n",
    "            else:\n",
    "                early_stop = False\n",
    "\n",
    "        return early_stop, get_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79dc7cc7-e20b-476a-be20-15ff1984a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    \"\"\"\n",
    "    Format elapsed time string.\n",
    "    \"\"\"\n",
    "    now = time.time()\n",
    "    elapsed_time = now - since\n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dcad401-64ea-4190-80be-4c554f8ee50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = []\n",
    "HIT_10 = []\n",
    "NDCG_5 = []\n",
    "NDCG_10 = []\n",
    "MRR = []\n",
    "steps = []\n",
    "epochs = []\n",
    "train_avg_loss = []\n",
    "train_recent_loss = []\n",
    "batches = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "069bd652-fe2f-4be9-81e6-7ccd7a2c4991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    try:\n",
    "        pretrained_word_embedding = torch.from_numpy(\n",
    "            np.load('../data/train/pretrained_word_embedding.npy')).float()\n",
    "    except FileNotFoundError:\n",
    "        pretrained_word_embedding = None\n",
    "    \n",
    "    model = Model(config, pretrained_word_embedding).to(device)\n",
    "\n",
    "    print(model)\n",
    "\n",
    "    dataset = BaseDataset('../data/train/behaviors_parsed.tsv',\n",
    "                          '../data/train/news_parsed.tsv')\n",
    "\n",
    "    print(f\"Load training dataset with size {len(dataset)}.\")\n",
    "\n",
    "    dataloader = iter(\n",
    "        DataLoader(dataset,\n",
    "                   batch_size=config.batch_size,\n",
    "                   shuffle=True,\n",
    "                   num_workers=config.num_workers,\n",
    "                   drop_last=True,\n",
    "                   pin_memory=True))\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    loss_full = []\n",
    "    exhaustion_count = 0\n",
    "    step = 0\n",
    "    epoch = 0\n",
    "    early_stopping = EarlyStopping()\n",
    "\n",
    "    for i in tqdm(range(1,config.num_epochs * len(dataset) // config.batch_size + 1),desc=\"Training\"):\n",
    "        try:\n",
    "            minibatch = next(dataloader)\n",
    "        except StopIteration:\n",
    "            exhaustion_count += 1\n",
    "            tqdm.write(f\"Training data exhausted for {exhaustion_count} times after {i} batches, reuse the dataset.\")\n",
    "            \n",
    "            epoch += 1\n",
    "            epochs.append(epoch)\n",
    "            model.eval()\n",
    "            val_auc, val_mrr, val_ndcg5, val_ndcg10 = evaluate(model, '../data/val', config.num_workers, 200000)\n",
    "            model.train()\n",
    "            steps.append(step)\n",
    "            AUC.append(val_auc)\n",
    "            MRR.append(val_mrr)\n",
    "            NDCG_5.append(val_ndcg5)\n",
    "            NDCG_10.append(val_ndcg10)\n",
    "            tqdm.write(\n",
    "                f\"Time {time_since(start_time)}, batches {i}, validation AUC: {val_auc:.4f}, validation MRR: {val_mrr:.4f}, validation nDCG@5: {val_ndcg5:.4f}, validation nDCG@10: {val_ndcg10:.4f}\"\n",
    "            )\n",
    "            \n",
    "            early_stop, get_better = early_stopping(-val_auc)\n",
    "            if early_stop:\n",
    "                tqdm.write('Early stop.')\n",
    "                break\n",
    "            elif get_better:\n",
    "                try:\n",
    "                    best_model_path = \"./path/LSTUR/〇〇.pth\"\n",
    "                    torch.save(model.state_dict(), best_model_path)\n",
    "                    print(\"Saved successfully!!!\")\n",
    "                except OSError as error:\n",
    "                    print(f\"OS error: {error}\")\n",
    "                    \n",
    "            dataloader = iter(\n",
    "                DataLoader(dataset,\n",
    "                           batch_size=config.batch_size,\n",
    "                           shuffle=True,\n",
    "                           num_workers=config.num_workers,\n",
    "                           drop_last=True,\n",
    "                           pin_memory=True))\n",
    "            minibatch = next(dataloader)\n",
    "\n",
    "        step += 1\n",
    "        \n",
    "        if model_name == 'LSTUR':\n",
    "            y_pred = model(minibatch[\"user\"], minibatch[\"clicked_news_length\"], minibatch[\"candidate_news\"], minibatch[\"clicked_news\"])\n",
    "\n",
    "        y = torch.zeros(len(y_pred)).long().to(device)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss_full.append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % config.num_batches_show_loss == 0:\n",
    "            batches.append(i)\n",
    "            train_avg_loss.append(np.mean(loss_full))\n",
    "            train_recent_loss.append(np.mean(loss_full[-100:]))\n",
    "            tqdm.write(\n",
    "                f\"Time {time_since(start_time)}, batches {i}, current loss {loss.item():.4f}, average loss: {np.mean(loss_full):.4f}, latest average loss: {np.mean(loss_full[-256:]):.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2165a4-aed3-4760-811e-80e83d6634c6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(f'Training model {model_name}')\n",
    "    train()\n",
    "\n",
    "# Visualization of results\n",
    "Graph(AUC,NDCG_5,NDCG_10,MRR,epochs,train_recent_loss,batches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maekawa",
   "language": "python",
   "name": "maekawa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
