# NRGETC
Code for our paper 
# "A News Recommendation Framework Utilizing ChatGPT: Estimating Target Audience and News Categories"
![Proposed News Recommendation Framework Illustration](pf.png)

# Description of folder structure.
```
ğŸ“¦ this-repo-name
â”œâ”€â”€ ğŸ“ src                # Main source code of the experiment
|   â”œâ”€â”€ ğŸ“„ config.py        # File for setting model parameters, etc.
|   â”œâ”€â”€ ğŸ“„ data_preprocess.py       # Data preprocessing file
|   â”œâ”€â”€ ğŸ“„ dataset.py        
|   â”œâ”€â”€ ğŸ“„ evaluate.py        # File to experiment with valuation data at the end of each epoch in the learning process.
|   â”œâ”€â”€ ğŸ“„ test.py        # Files for testing
|   â”œâ”€â”€ ğŸ“„ view.py        # Files for drawing
â”‚   â””â”€â”€ ğŸ“ (path)         # Save the best parameters in the training of each model.
â”œâ”€â”€ ğŸ“ (data)             # This folder must be created according to the Data Download instructions below.
â”œâ”€â”€ ğŸ“ Generated_data     # Stores information generated by GPT (targets and categories)
    â”œâ”€â”€ ğŸ“„ Generated_Target.csv   
â”‚   â””â”€â”€ ğŸ“„ Generated_Category.csv
â”œâ”€â”€ ğŸ“ GPT_Augmentation     # Information extension using ChatGPT's API.
    â”œâ”€â”€ ğŸ“„ GPT_API.ipynb
â”‚   â””â”€â”€ ğŸ“„ all_news_title.csv
â”œâ”€â”€ ğŸ“„ README.md          # ãƒªãƒã‚¸ãƒˆãƒªã®èª¬æ˜æ›¸
â””â”€â”€ ğŸ“„ requirements.txt   # å¿…è¦ãªPythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
(ã€‡ã€‡) represents the folder that needs to be created when using this code. Not in this current repository.
```

# Data Download
Download and preprocess the data.
```bash
mkdir data && cd data
# Download GloVe pre-trained word embedding
wget https://nlp.stanford.edu/data/glove.840B.300d.zip
sudo apt install unzip
unzip glove.840B.300d.zip -d glove
rm glove.840B.300d.zip

# Download MIND dataset
# By downloading the dataset, you agree to the [Microsoft Research License Terms](https://go.microsoft.com/fwlink/?LinkID=206977). For more detail about the dataset, see https://msnews.github.io/.
# Uncomment the following lines to use the MIND Small dataset (Note MIND Small doesn't have a test set, In our paper we use the validation data from the original dataset as test data in this experiment.
# In addition, the training data in the original dataset are divided into the training data (first 5 days) and the validation data (last 1 day) for this experiment. So you need to do the splitting of the data set after downloading:)
wget https://mind201910small.blob.core.windows.net/release/MINDsmall_train.zip https://mind201910small.blob.core.windows.net/release/MINDsmall_dev.zip
unzip MINDsmall_train.zip -d train
unzip MINDsmall_dev.zip -d val
rm MINDsmall_*.zip
